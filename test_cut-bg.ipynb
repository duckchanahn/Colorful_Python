{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 배경 제거 -> 흰색 노란색 머리의 경우 검은 배경으로 사진 찍을 것을 요청\n",
    "#     -> 배경 제거 완료했고, 첫 이미지의 배경이 검은색인지 흰색인지만 판단하기\n",
    "#     -> 이것도 그냥 적도록 하면 안되나?\n",
    "#     -> 판단도 참 애매한데\n",
    "#     -> 근데 이게 아예 검은색 아예 흰색이라 실제 배경으로 테스트 해봐야할 듯\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 이미지 배경제거\n",
    "# 얼굴 좌표를 기준으로 사진 커팅\n",
    "# 새로운 사진(얼굴 좌표로 커팅 된 배경되지 않은) 불러오기\n",
    "# 좌표 비교 -> (제거된 자표 & !얼굴범위) ? 제거 : continue\n",
    "# 배경 제거 및 얼굴 좌표 생성 완료\n",
    "# 이후에 시간이 남으면 사용자에게 얼굴 추출된 사진을 보여주고 잘못된 좌표 선택 가능하도록 업데이트\n",
    "\n",
    "\n",
    "# Exception\n",
    "# 머리가 은색이나 흰색이면 어떡해? -> 동방예의지국인데 은색 머리..?\n",
    "# 완전 생 노란색 머리도 지워지네 http://image.auction.co.kr/itemimage/fd/1c/12/fd1c12696.jpg -> 노란 머리가 말이야? \n",
    "# 무조건 흰색 배경 앞에서 찍을 것 !!!\n",
    "\n",
    "\n",
    "###### ++ 대머리는 어떡해? -> 출시할 거 아니니까 괜찮아\n",
    "\n",
    "\n",
    "\n",
    "# 떠올라버렸어 이거 장난아니야\n",
    "# 밝은 머리의 경우 -> 검은 배경으로\n",
    "# 어두운 머리의 경우 -> 흰색 배경으로\n",
    "\n",
    "# --> 배경이 어두울 경우 색반전\n",
    "# --> 배경제거\n",
    "# --> 배경제거 버전을 기준으로 기존 사진에서 배경 다시 제거\n",
    "# --> 얼굴 검출\n",
    "# --> 검출되지 않은 좌표 && 제거되지 않은 좌표 == 모발\n",
    "# /* 색반전 코드\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"lenna.png\")\n",
    "# out = img.copy()\n",
    "# out = 255 - out\n",
    "# cv2.imshow(\"original\", img)\n",
    "# cv2.imshow(\"flip\", out)\n",
    "# cv2.waitKey(0)\n",
    "# */\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 생각생각 생각생각\n",
    "# 1. 머리색 추측 \n",
    "# /* 배경 제거 후 얼굴 좌표 위 일정 영역을 탐색하면 지워졌는지 안 지워졌는지 알 수 있음\n",
    "#    혹은 탐색한 영역의 평균 색 (지워진 영역을 제외하고)으로 탐지\n",
    "# */\n",
    "# 검은머리 ~ 갈색머리 등 어두운 색일 경우엔 임계값 낮출 시 모발 동공만 남음 (흰색 배경 기준)\n",
    "# -> 쉽게 모발 동공을 구할 수 있음\n",
    "# -> 렌즈 끼고 찍은 사람 윌스미스 마렵네\n",
    "# 흰색머리 ~ 노란 머리 등 밝은 색일 경우엔 어떡해?\n",
    "# -> 여행 전 염색이 필요합니다.\n",
    "# ->\n",
    "# 오늘 아침에 보라색 머리도 보고 반은 검은색 반은 노란색도 봤는데 경우의 수가 너무 많은데?\n",
    "# 2. 통계에서 일정 수치가 지워졌더라도 남은 수치로 충분히 추측이 가능함\n",
    "# 지워진 부분을 두고 얼굴 좌표 기준 위쪽 애들 비교\n",
    "# -> 아무리 머리가 흰색이어도 진짜 백발이 아닌 이상 어느정도 남기에 남은 머리로 퍼스널컬러를 추측\n",
    "# -> 이게 최곤가?\n",
    "# 3. 일정 임계값을 정한 뒤 그로부터 5~10씩 계속 높이기\n",
    "# -> 얼굴 좌표 기준으로 일정 비율의 범위를 정하고 계속해서 임계값을 임계값을 높임\n",
    "# -> 처음엔 계속해서 지워진 머리가 채워지기 시작\n",
    "# -> 첫 낮은 임계값 기준 + 임의로 정한 일정 비율 범위 내 모발을 채워나감\n",
    "\n",
    "\n",
    "# 하ㄹㄹ-르 라는 애가 있는데 이거 써볼까? 설명글이 너무 길어서 난독증 오는데 할 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "h :  79\n",
      "w :  72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# imageUrl = 'img/test_img_brown_1.jpg'\n",
    "# imageUrl = 'img/test_img_black_1.jpg'\n",
    "imageUrl = 'img/test_img_black_3.jpg'\n",
    "# imageUrl = 'img/test_img_black_2.jpg'\n",
    "imageUrl = 'img/eye_resize.jpg'\n",
    "\n",
    "# 이미지 불러오기\n",
    "img = cv2.imread(imageUrl)\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "# img = 255 - img # 이미지 배경이 검인지 흰인지 판단하는 함수 필요 \n",
    "\n",
    "# 변환 graky\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 임계값 조절\n",
    "mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "# mask = cv2.adaptiveThreshold(gray, 10, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 2)[1]\n",
    "# (gray, 120, cv2.ADAPTIVE_THRESH_MEAN_C, 255, cv2.THRESH_BINARY, 15, 2)[1]\n",
    "# (img,  255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2. THRESH_BINARY,15,2)\n",
    "# (img  ,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,15,2)\n",
    "\n",
    "# mask\n",
    "mask = 255 - mask\n",
    "\n",
    "# morphology 적용\n",
    "# borderconstant 사용\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# anti-alias the mask\n",
    "# blur alpha channel\n",
    "mask = cv2.GaussianBlur(mask, (0,0), sigmaX=2, sigmaY=2, borderType = cv2.BORDER_DEFAULT)\n",
    "\n",
    "# linear stretch so that 127.5 goes to 0, but 255 stays 255\n",
    "mask = (2*(mask.astype(np.float32))-255.0).clip(0,255).astype(np.uint8)\n",
    "\n",
    "# put mask into alpha channel\n",
    "result = img.copy()\n",
    "result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "result[:, :, 3] = mask\n",
    "\n",
    "\n",
    "# result = 255 - result\n",
    "\n",
    "h, w, c = result.shape\n",
    "\n",
    "print('h : ', h)\n",
    "print('w : ', w)\n",
    "\n",
    "# for x in range(0, w):\n",
    "#     for y in range(0, h):\n",
    "#         if(result[y, x][0] != 255 & result[y, x][1] != 255 & result[y, x][2] != 255):\n",
    "#             result[y, x][0] = 255 - result[y, x][0]\n",
    "#             result[y, x][1] = 255 - result[y, x][1]\n",
    "#             result[y, x][2] = 255 - result[y, x][2]\n",
    "\n",
    "            \n",
    "# return result\n",
    "            \n",
    "# 저장\n",
    "resultimg_url = 'img/ttt.png'\n",
    "cv2.imwrite(resultimg_url, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def cutBackground_darkHair(img):\n",
    "    # 변환 graky\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 임계값 조절\n",
    "    mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # mask\n",
    "    mask = 255 - mask\n",
    "\n",
    "    # morphology 적용\n",
    "    # borderconstant 사용\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # anti-alias the mask\n",
    "    # blur alpha channel\n",
    "    mask = cv2.GaussianBlur(mask, (0,0), sigmaX=2, sigmaY=2, borderType = cv2.BORDER_DEFAULT)\n",
    "\n",
    "    # linear stretch so that 127.5 goes to 0, but 255 stays 255\n",
    "    mask = (2*(mask.astype(np.float32))-255.0).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    # put mask into alpha channel\n",
    "    result = img.copy()\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "    result[:, :, 3] = mask\n",
    "\n",
    "    return result\n",
    "\n",
    "resultimg_url = 'img/eye_result.jpg'\n",
    "# resultimg_url = 'img/test_img_black_3.jpg'\n",
    "# resultimg = 'translated_yellowHair.png'\n",
    "\n",
    "# 이미지 불러오기\n",
    "resultimg = cv2.imread(resultimg_url)\n",
    "img_eye = cutBackground_darkHair(resultimg)\n",
    "\n",
    "resultimg_url = 'img/' + 'eye_cut' + '_result.png'\n",
    "cv2.imwrite(resultimg_url, np.float32(img_eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getEyes(img, personal):\n",
    "#     json_facial_points = json.loads(str(res.json()['result']['faces'])[1:-1].replace('\\'', '\\\"'))['facial_points']\n",
    "#     h_o, w_o, c = img.shape\n",
    "#     polygon_face = []\n",
    "    \n",
    "#     for position in json_facial_points['left_eye']:\n",
    "#         point = (int(position[0]*w_o), int(position[1]*h_o))\n",
    "#         polygon_face.append(point)\n",
    "\n",
    "#     # convert to numpy (for convenience)\n",
    "#     result_img = np.asarray(img)\n",
    "\n",
    "#     # create new image (\"1-bit pixels, black and white\", (width, height), \"default color\")\n",
    "#     mask_img = Image.new('1', (result_img.shape[1], result_img.shape[0]), 0)\n",
    "\n",
    "#     ImageDraw.Draw(mask_img).polygon(polygon_face, outline=1, fill=1)\n",
    "#     mask = np.array(mask_img)\n",
    "\n",
    "#     # assemble new image (uint8: 0-255)\n",
    "#     new_img_array = np.empty(result_img.shape, dtype='uint8')\n",
    "\n",
    "#     # copy color values (RGB)\n",
    "#     new_img_array[:,:,:3] = result_img[:,:,:3]\n",
    "\n",
    "#     # filtering image by mask\n",
    "#     new_img_array[:,:,0] = new_img_array[:,:,0] * mask\n",
    "#     new_img_array[:,:,1] = new_img_array[:,:,1] * mask\n",
    "#     new_img_array[:,:,2] = new_img_array[:,:,2] * mask\n",
    "\n",
    "#     # back to Image from numpy\n",
    "#     result_img = Image.fromarray(new_img_array, \"RGB\")\n",
    "\n",
    "#     resultimg_url = 'img/' + 'eye' + '_result.jpg'\n",
    "#     cv2.imwrite(resultimg_url, np.float32(result_img))\n",
    "    \n",
    "    h_o, w_o, c = img.shape\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "#     personal_low = [personal[0]-10, personal[1], personal[2]]\n",
    "#     personal_high = [255, 255, 255]\n",
    "#     low = lab2rgb(personal_low)\n",
    "#     high = lab2rgb(personal_high)\n",
    "    \n",
    "#     img_cuteye = cv2.inRange(img, (low[0], low[1], low[2]), (high[0], high[2], high[2])) # 이거 기준 하얀색은 제거\n",
    "#     img_cuteye = cv2.inRange(img, (240, 240, 240), (255, 255, 255)) # 이거 기준 하얀색은 제거\n",
    "    \n",
    "#     resultimg_url = 'img/' + 'test_cuteye' + '_result.jpg'\n",
    "#     cv2.imwrite(resultimg_url, np.float32(img_cuteye))\n",
    "    \n",
    "#     print('img : ', type(img))\n",
    "#     print('img_cut : ', type(img_cutHead))\n",
    "    \n",
    "\n",
    "#     for position_x in range(0, w_o):\n",
    "#         for position_y in range(0, h_o):\n",
    "# #             print((img_cuteye[position_y,position_x]!= (0, 0, 0))[0] == True)\n",
    "#             condition = img_cuteye[position_y, position_x] != (0, 0, 0)\n",
    "#             if (condition[0] and condition[1] and condition[2]:\n",
    "#                 print(\"before : \", img_cuteye[position_y,position_x])\n",
    "#                 img[position_y, position_x][0] = 0\n",
    "#                 img[position_y, position_x][1] = 0\n",
    "#                 img[position_y, position_x][2] = 0\n",
    "    \n",
    "    print('==========================================================================')\n",
    "    \n",
    "\n",
    "#     for position_x in range(0, w_o):\n",
    "#         for position_y in range(0, h_o):\n",
    "#             print(\"before : \", img[position_y,position_x])\n",
    "    \n",
    "    h_o, w_o, c = img.shape\n",
    "    for position_x in range(0, w_o):\n",
    "        for position_y in range(0, h_o):\n",
    "            condition_r = img[position_y, position_x][0] < 70\n",
    "            condition_g = img[position_y, position_x][1] < 70\n",
    "            condition_b = img[position_y, position_x][2] < 70\n",
    "            if (condition_r == False and condition_g == False and condition_b == False):\n",
    "                img[position_y, position_x] = [0, 0, 0]\n",
    "            \n",
    "    return np.float32(img)\n",
    "\n",
    "resultimg_url = 'img/eye_resize.jpg'\n",
    "# resultimg_url = 'img/eye_result.jpg'\n",
    "# resultimg_url = 'img/test_img_black_3.jpg'\n",
    "\n",
    "# 이미지 불러오기\n",
    "resultimg = cv2.imread(resultimg_url)\n",
    "img_eye = getEyes(resultimg, (255, 255, 255))\n",
    "\n",
    "resultimg_url = 'img/' + 'eye_cut' + '_result.png'\n",
    "cv2.imwrite(resultimg_url, np.float32(img_eye))\n",
    "\n",
    "resultimg_url = 'img/' + 'eye_cut' + '_result.jpg'\n",
    "cv2.imwrite(resultimg_url, np.float32(img_eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9d2ba09aef25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 이미지 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresultimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultimg_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresultimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2BGRA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "resultimg_url = 'img/eye_result.jpg'\n",
    "# resultimg = 'translated_yellowHair.png'\n",
    "\n",
    "# 이미지 불러오기\n",
    "resultimg = cv2.imread(resultimg_url)\n",
    "\n",
    "resultimg = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "# resultimg[:, :, 3] = resultimg\n",
    "\n",
    "h, w, c = resultimg.shape\n",
    "\n",
    "for x in range(0, w):\n",
    "    for y in range(0, h):\n",
    "        if(resultimg[x, y][0] != 0 & resultimg[x, y][1] != 0 & resultimg[x, y][2] != 0):\n",
    "            result[x, y][0] = img[x, y][0]\n",
    "            result[x, y][1] = img[x, y][1]\n",
    "            result[x, y][2] = img[x, y][2]\n",
    "\n",
    "\n",
    "new_image_url = \"/img/new_image.png\"\n",
    "cv2.imshow(new_image_url, resultimg)\n",
    "cv2.imwrite(new_image_url, resultimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-505a0e61d774>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnew_image_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/img/new_image.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_image_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'img'"
     ]
    }
   ],
   "source": [
    "img = new_image\n",
    "\n",
    "img = img[:, :, ::-1]\n",
    "\n",
    "new_image_url = \"/img/new_image.png\"\n",
    "cv2.imwrite(new_image_url, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 자르기 (x1 y1 x2 y2)\n",
    "\n",
    "cropped_image = pil_image.crop((480, 520, 580, 580))\n",
    "cropped_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
